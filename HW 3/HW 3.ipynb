{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c24f221f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy.optimize\n",
    "from sklearn import svm\n",
    "import numpy\n",
    "import string\n",
    "import random\n",
    "import string\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e470ab9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a39276b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assertFloat(x):\n",
    "    assert type(float(x)) == float\n",
    "\n",
    "def assertFloatList(items, N):\n",
    "    assert len(items) == N\n",
    "    assert [type(float(x)) for x in items] == [float]*N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cec761e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        u,b,r = l.strip().split(',')\n",
    "        r = int(r)\n",
    "        yield u,b,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24e236ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c6c1866",
   "metadata": {},
   "outputs": [],
   "source": [
    "allRatings = []\n",
    "for l in readCSV(\"assignment1/train_Interactions.csv.gz\"):\n",
    "    allRatings.append(l)\n",
    "ratingsTrain = allRatings[:190000]\n",
    "ratingsValid = allRatings[190000:]\n",
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "usersPerItem = defaultdict(set)\n",
    "for u,b,r in ratingsTrain:\n",
    "    ratingsPerUser[u].append((b,r))\n",
    "    ratingsPerItem[b].append((u,r))\n",
    "    usersPerItem[b].add(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acee3f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from baseline code\n",
    "bookCount = defaultdict(int)\n",
    "totalRead = 0\n",
    "\n",
    "for user,book,_ in readCSV(\"assignment1/train_Interactions.csv.gz\"):\n",
    "    bookCount[book] += 1\n",
    "    totalRead += 1\n",
    "\n",
    "mostPopular = [(bookCount[x], x) for x in bookCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return1.add(i)\n",
    "    if count > totalRead/2: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6a33a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Q1\n",
    "len(return1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af564262",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = set()\n",
    "users = set()\n",
    "userBookRead = defaultdict(set)\n",
    "\n",
    "for user, book, _ in allRatings:\n",
    "    books.add(book)\n",
    "    users.add(user)\n",
    "    userBookRead[user].add(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d120e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "negativeRatingsValid = []\n",
    "for user, book, _ in ratingsValid:\n",
    "    notRead = list(books.difference(userBookRead[user]))\n",
    "    negativeSample = random.choice(notRead)\n",
    "    negativeRatingsValid.append((user, negativeSample, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "980f1cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ratingsValid)):\n",
    "    u,b,_ = ratingsValid[i]\n",
    "    ratingsValid[i] = (u,b, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b9cdba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = ratingsValid+negativeRatingsValid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa5cc41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for _,book,_ in validation:\n",
    "    if book in return1:\n",
    "        predictions.append(True)\n",
    "    else:\n",
    "        predictions.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd2ddefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "y = [t[2] for t in validation]\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "050f0d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, y):\n",
    "    TP = sum([(p and l) for (p,l) in zip(predictions, y)])\n",
    "    TN = sum([(not p and not l) for (p,l) in zip(predictions, y)])\n",
    "    return (TP+TN)/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b0261d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q1'] = accuracy(predictions, y)\n",
    "assertFloat(answers['Q1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a063f0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97d5c42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "return2 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return2.add(i)\n",
    "    if count > totalRead/1.4: break # 1.4 means threashold of 71.43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "992b5ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = []\n",
    "for _,book,_ in validation:\n",
    "    if book in return2:\n",
    "        predictions2.append(True)\n",
    "    else:\n",
    "        predictions2.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24cfab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q2'] = [71.43, accuracy(predictions2, y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d26ab3d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[71.43, 0.75495]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b71af344",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q2'][0])\n",
    "assertFloat(answers['Q2'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64a4a38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4aa020c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e956d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions3 = []\n",
    "threshold = .003\n",
    "for user,book,_ in validation:\n",
    "    maxJaccard = 0\n",
    "    for bPrime,_ in ratingsPerUser[user]:\n",
    "        maxJaccard = max(maxJaccard, Jaccard(usersPerItem[book], usersPerItem[bPrime]))\n",
    "    if threshold < maxJaccard:\n",
    "        predictions3.append(True)\n",
    "    else:\n",
    "        predictions3.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23421d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69735"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(predictions3, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "029ce3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q3'] = accuracy(predictions3, y)\n",
    "assertFloat(answers['Q3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b60f7040",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89388625",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions4 = []\n",
    "threshold = .045\n",
    "for user,book,_ in validation:\n",
    "    maxJaccard = 0\n",
    "    for bPrime,_ in ratingsPerUser[user]:\n",
    "        maxJaccard = max(maxJaccard, Jaccard(usersPerItem[book], usersPerItem[bPrime]))\n",
    "    if threshold < maxJaccard or book in return2:\n",
    "        predictions4.append(True)\n",
    "    else:\n",
    "        predictions4.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "edfc5dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q4'] = accuracy(predictions4, y)\n",
    "assertFloat(answers['Q4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77a7ee95",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d1bf8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(user, book):\n",
    "    maxJaccard = 0\n",
    "    for bPrime,_ in ratingsPerUser[user]:\n",
    "        maxJaccard = max(maxJaccard, Jaccard(usersPerItem[book], usersPerItem[bPrime]))\n",
    "    if threshold < maxJaccard or book in return2:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "54c8cc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(\"predictions_Read.csv\", \"w\", newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for l in open(\"assignment1/pairs_Read.csv\"):\n",
    "        if l.startswith(\"userID\"):\n",
    "            writer.writerow([\"userID\", \"bookID\", \"prediction\"])\n",
    "            continue\n",
    "        u,b = l.strip().split(',')\n",
    "        row = [u, b, predict(u,b)]\n",
    "        writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4291d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q5'] = \"I confirm that I have uploaded an assignment submission to gradescope\"\n",
    "assert type(answers['Q5']) == str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "99b935f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ad30e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "allRatings = []\n",
    "for l in readCSV(\"assignment1/train_Interactions.csv.gz\"):\n",
    "    allRatings.append(l)\n",
    "ratingsTrain = allRatings[:190000]\n",
    "ratingsValid = allRatings[190000:]\n",
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "usersPerItem = defaultdict(set)\n",
    "userBiases = defaultdict(float)\n",
    "itemBiases = defaultdict(float)\n",
    "for u,b,r in ratingsTrain:\n",
    "    ratingsPerUser[u].append((b,r))\n",
    "    ratingsPerItem[b].append((u,r))\n",
    "    usersPerItem[b].add(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f830456a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences) / len(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11cc02a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6802113179223874"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = sum([r for _,_,r in ratingsTrain])/len(ratingsTrain)\n",
    "alwaysPredictMean = [mean for d in ratingsValid]\n",
    "y = [d[2] for d in ratingsValid]\n",
    "MSE(alwaysPredictMean, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5714a5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(ratingsTrain)\n",
    "nUsers = len(ratingsPerUser)\n",
    "nItems = len(ratingsPerItem)\n",
    "users = list(ratingsPerUser.keys())\n",
    "items = list(ratingsPerItem.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1304a094",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7b50420d",
   "metadata": {},
   "outputs": [],
   "source": [
    "userBiases = defaultdict(float)\n",
    "itemBiases = defaultdict(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a955850",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(user, item):\n",
    "    if user in userBiases and item in itemBiases:\n",
    "        return alpha + userBiases[user] + itemBiases[item]\n",
    "    elif user in userBiases:\n",
    "        return alpha + userBiases[user]\n",
    "    elif item in itemBiases:\n",
    "        return alpha + itemBiases[item]\n",
    "    else:\n",
    "        return alpha "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fba4c440",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [d[2] for d in ratingsTrain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f2ca45cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for u in users:\n",
    "    userBiases[u] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9543361f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in items:\n",
    "    itemBiases[i] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "28aed8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamb = 1\n",
    "for i in range(50):\n",
    "    dalpha = 0\n",
    "    for u,b,r in ratingsTrain:\n",
    "        dalpha += r - (userBiases[u]+itemBiases[b])\n",
    "    alpha = dalpha/N\n",
    "    \n",
    "    dUserBiases = defaultdict(float)\n",
    "    for u in users:\n",
    "        dUserBiases[u] = 0.0\n",
    "    dItemBiases = defaultdict(float)\n",
    "    for i in items:\n",
    "        dItemBiases[u] = 0.0\n",
    "        \n",
    "    for user in userBiases:\n",
    "        for book,rating in ratingsPerUser[user]:\n",
    "            dUserBiases[user] += rating - (alpha+itemBiases[book])\n",
    "        dUserBiases[user] = dUserBiases[user]/(lamb+len(ratingsPerUser[user]))\n",
    "    userBiases = dUserBiases\n",
    "    for item in itemBiases:\n",
    "        for u, r in ratingsPerItem[item]:\n",
    "            dItemBiases[item] += r - (alpha+userBiases[u])\n",
    "        dItemBiases[item] = dItemBiases[item]/(lamb+len(ratingsPerItem[item]))\n",
    "    itemBiases = dItemBiases\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b8072807",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = [prediction(u,b) for u,b,_ in ratingsValid]\n",
    "y = [r for _,_,r in ratingsValid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7f52241a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = MSE(pred,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6406549c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4345367814517573"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bf6809f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q9'] = mse\n",
    "assertFloat(answers['Q9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2da65f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cb78f882",
   "metadata": {},
   "outputs": [],
   "source": [
    "sortusers = sorted(userBiases.items(), key=lambda kv: kv[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9700fcc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('u19874911', 1.8286822382106807)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortusers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dbb2a163",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q10'] = [sortusers[0][0], sortusers[-1][0], float(sortusers[0][1]), float(sortusers[-1][1])]\n",
    "assert [type(x) for x in answers['Q10']] == [str, str, float, float]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a8fa7227",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "da97ad41",
   "metadata": {},
   "outputs": [],
   "source": [
    "for u in users:\n",
    "    userBiases[u] = 0.0\n",
    "for i in items:\n",
    "    itemBiases[i] = 0.0\n",
    "lamb = 5\n",
    "for i in range(50):\n",
    "    dalpha = 0\n",
    "    for u,b,r in ratingsTrain:\n",
    "        dalpha += r - (userBiases[u]+itemBiases[b])\n",
    "    alpha = dalpha/N\n",
    "    \n",
    "    dUserBiases = defaultdict(float)\n",
    "    for u in users:\n",
    "        dUserBiases[u] = 0.0\n",
    "    dItemBiases = defaultdict(float)\n",
    "    for i in items:\n",
    "        dItemBiases[u] = 0.0\n",
    "        \n",
    "    for user in userBiases:\n",
    "        for book,rating in ratingsPerUser[user]:\n",
    "            dUserBiases[user] += rating - (alpha+itemBiases[book])\n",
    "        dUserBiases[user] = dUserBiases[user]/(lamb+len(ratingsPerUser[user]))\n",
    "    userBiases = dUserBiases\n",
    "    for item in itemBiases:\n",
    "        for u, r in ratingsPerItem[item]:\n",
    "            dItemBiases[item] += r - (alpha+userBiases[u])\n",
    "        dItemBiases[item] = dItemBiases[item]/(lamb+len(ratingsPerItem[item]))\n",
    "    itemBiases = dItemBiases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "18c1975c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.381473022248055"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2 = [prediction(u,b) for u,b,_ in ratingsValid]\n",
    "y = [r for _,_,r in ratingsValid]\n",
    "validMSE = MSE(pred2,y)\n",
    "validMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a052ad1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q11'] = (5, validMSE)\n",
    "assertFloat(answers['Q11'][0])\n",
    "assertFloat(answers['Q11'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ab6497b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(\"predictions_Rating.csv\", \"w\", newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for l in open(\"assignment1/pairs_Rating.csv\"):\n",
    "        if l.startswith(\"userID\"):\n",
    "            writer.writerow([\"userID\", \"bookID\", \"rating\"])\n",
    "            continue\n",
    "        u,b = l.strip().split(',')\n",
    "        row = [u, b, prediction(u,b)]\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0738bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7b7b3c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"answers_hw3.txt\", 'w')\n",
    "f.write(str(answers) + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb2a0a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
